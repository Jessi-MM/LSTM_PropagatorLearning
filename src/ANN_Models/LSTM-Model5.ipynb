{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d0a5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import integrate\n",
    "\n",
    "import h5py\n",
    "\n",
    "\n",
    "#import matplotlib.colors as mcolors\n",
    "#from matplotlib import rcParams\n",
    "\n",
    "#import os\n",
    "#-----\n",
    "\n",
    "\n",
    "# Enable interactive plot\n",
    "#%matplotlib notebook\n",
    "#plt.style.use('pusheen')  # to poster\n",
    "color = ['#83b692','#f9ada0', '#f9627d', '#c65b7c', '#5b3758']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15517338",
   "metadata": {},
   "source": [
    "from matplotlib import rc\n",
    "\n",
    "rc('text', usetex=True)\n",
    "rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "\n",
    "color1 = ['#ff595e','#ffca3a','#8ac926','#1982c4','#6a4c93']\n",
    "color = ['#83b692','#f9ada0', '#f9627d', '#c65b7c', '#5b3758']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cd442",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15a6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=200  # number of steps on trajectories\n",
    "n_grid = 32  # number of points on grid\n",
    "delta = True # True: y_pred = Psi_t -Psi_{t-1}; else: y_pred = Psi_t \n",
    "\n",
    "if delta == True:\n",
    "    path_dat = '../DataLoader/Data/datadelta.h5'\n",
    "else:\n",
    "    path_dat = '../DataLoader/Data/data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6643fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Propagator_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path, data, targets, transform=True):\n",
    "        \n",
    "        self.data = data  # path of data X\n",
    "        self.targets = targets  # path of labels y\n",
    "        self.transform = transform  # to tensor\n",
    "        \n",
    "        self.hf = h5py.File(path, 'r')  # reading data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        X = self.hf.get(self.data)[index]\n",
    "        y = self.hf.get(self.targets)[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            X = torch.tensor(X)\n",
    "            y = torch.tensor(y)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        \n",
    "        tot = len(self.hf.get(self.data))\n",
    "        #tot = 100\n",
    "        \n",
    "        return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e090cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Propagator_Dataset(path=path_dat, data='dataset_X', targets='dataset_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d11a37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of data  8000\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "print('Total of data ', dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3b6edf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.1\n",
    "validation_split = 0.2  \n",
    "shuffle_dataset = False\n",
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ceb51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data indices for training and validation splits:\n",
    "indices = list(range(dataset_size))\n",
    "split_val = int(np.floor(validation_split * dataset_size))\n",
    "split_test = int(np.floor(test_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "\n",
    "test_indices = indices[0:split_test] \n",
    "val_indices = indices[split_test:split_test+split_val]   \n",
    "train_indices = indices[split_test+split_val:]\n",
    "\n",
    "#train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cae55936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of train samples: 5600\n",
      "Total of validation samples: 1600\n",
      "Total of test samples: 800\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of train samples: {len(train_sampler)}\")\n",
    "print(f\"Total of validation samples: {len(val_sampler)}\")\n",
    "print(f\"Total of test samples: {len(test_sampler)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29dafb6",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d7fb09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0c6c7",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9db763be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c493b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "Shape of X in train loader: torch.Size([10, 200, 96])\n",
      "Shape of y in train loader: torch.Size([10, 200, 64])\n",
      "Batch size: 10\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(\"Train data:\")\n",
    "    print(f\"Shape of X in train loader: {X.shape}\")\n",
    "    print(f\"Shape of y in train loader: {y.shape}\")\n",
    "    print(f\"Batch size: {X.size(0)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3216f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display features and label.\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "\n",
    "X_vis = train_features[0].squeeze()\n",
    "y_vis = train_labels[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60e84b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_n = torch.linspace(-1.5,1.5,32)\n",
    "time = int(0)  # from 0 to 199\n",
    "\n",
    "In_real_vis = X_vis[time,0:n_grid]\n",
    "In_imag_vis = X_vis[time,n_grid:n_grid*2]\n",
    "In_pote = X_vis[time,n_grid*2:]\n",
    "\n",
    "Ou_real_vis = y_vis[time,0:n_grid]\n",
    "Ou_imag_vis = y_vis[time,n_grid:n_grid*2]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "\n",
    "# Lenght: au -> Angstroms & au -> kcal/mol\n",
    "axs[0].plot(r_n, In_pote*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "axs[0].plot(r_n, In_real_vis*30, label=\"$\\psi_{real}(r, t)$\", color = color[0])  # Escaled\n",
    "axs[0].plot(r_n, In_imag_vis*30, label=\"$\\psi_{imag}(r, t)$\", color=color[1])  # Escaled\n",
    "axs[0].set_title(\"Input\")\n",
    "\n",
    "axs[1].plot(r_n, (In_real_vis + Ou_real_vis)*30, label=\"$\\psi_{real}(r, t+1)$\", color = color[0])  # Escaled\n",
    "axs[1].plot(r_n, (In_imag_vis + Ou_imag_vis)*30, label=\"$\\psi_{imag}(r, t+1)$\", color = color[1])  # Escaled\n",
    "axs[1].set_title(\"Output\")\n",
    "\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    ax.set_ylim([-15, 50])\n",
    "    ax.legend()\n",
    "    ax.set(xlabel='Position [$\\AA$]', ylabel='Energy [Kcal/mol]')\n",
    "\n",
    "plt.gcf().set_size_inches(8, 3)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dae950",
   "metadata": {},
   "source": [
    "## LSTM model\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95dad5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36a3c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1716ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_output, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_output = num_output  # number of output\n",
    "        self.num_layers = num_layers  # number of layers\n",
    "        self.input_size = input_size  # input size\n",
    "        self.hidden_size = hidden_size  # hidden state\n",
    "        self.seq_length = seq_length  # sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True).to(device) #lstm\n",
    "        \n",
    "        #self.fc_1 =  nn.Linear(hidden_size, 1024) #fully connected 1\n",
    "\n",
    "        #self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_output).to(device) #fully connected last layer\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        #hn = hn.view(-1,self.hidden_size) #reshaping the data for Dense layer next\n",
    "        #out = self.relu(hn)\n",
    "        #out = self.fc_1(out) #first Dense\n",
    "        #out = self.relu(output) #relu\n",
    "        out = self.fc(output) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "203deddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = n_grid*3  # number of features: 32 real part +32 complex part +32 potential\n",
    "hidden_size = 1024  # number of features in hidden state\n",
    "num_layers = 2  # number of stacked lstm layers\n",
    "num_output = n_grid*2  # number of output: 32 real part + 32 complex part\n",
    "sequence_len = seq_len # lenght of time steps (1 fs each one) total 5 fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "baeb44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(num_output, input_size, hidden_size, num_layers, sequence_len) #our lstm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b5990f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function and optimizer\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)  #weight_decay=0.01 <- default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f90b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('../../src/Models/06-08-23_290EPOCHS.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "191f61c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(96, 1024, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=1024, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a434ec8",
   "metadata": {},
   "source": [
    "## Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "13608c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_overlap(Psi_true, Psi_ANN, X):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Psi_true: Evolution of wavepacket from dataset test, Shape: (batch size, sequence lenght, 64)\n",
    "    Psi_ANN: Evolution of wavepacket predicted with the model, Shape: (batch size, sequence lenght, 64)\n",
    "    X : Evolution of wavepacket at time t-1\n",
    "    \n",
    "    Output:\n",
    "    S: Absolute magnitude\n",
    "    angle: phase\n",
    "    Characterizes the quality of the predictions. See equation (11) of Main article\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Psi_true_re = Psi_true[:,:,0:n_grid] + X[:,:,0:n_grid]   # realpart of wavepacket predicted\n",
    "    Psi_true_im = Psi_true[:,:,n_grid:n_grid*2] + X[:,:,n_grid:n_grid*2]  # imaginary part of wavepacket predicted \n",
    "    Psi_t = torch.view_as_complex(torch.stack((Psi_true_re,Psi_true_im), -1)).to(device)\n",
    "    \n",
    "    Psi_ANN_re = Psi_ANN[:,:,0:n_grid]+ X[:,:,0:n_grid]  # realpart of wavepacket predicted\n",
    "    Psi_ANN_im = -(Psi_ANN[:,:,n_grid:n_grid*2]+ X[:,:,n_grid:n_grid*2])  # imaginary part of wavepacket predicted (- because conjugate)\n",
    "    Psi_A = torch.view_as_complex(torch.stack((Psi_ANN_re,Psi_ANN_im), -1)).to(device)\n",
    "    \n",
    "    overl = Psi_A*Psi_t\n",
    "    \n",
    "    # Integrate over r (real integral + complex integral)\n",
    "    # Trapezoid method in the grid r_n (angstroms -> au)\n",
    "    \n",
    "    r_n = (torch.linspace(-1.5,1.5,32)*(1/0.5291775)).to(device)\n",
    "    overl_real = overl.real\n",
    "    overl_imag = overl.imag\n",
    "    \n",
    "    real_integ = torch.trapz(overl_real, r_n).to(device)\n",
    "    imag_integ = torch.trapz(overl_imag, r_n).to(device)\n",
    "    \n",
    "    # Covert to phase and magnitude of the complex result\n",
    "    S =  torch.sqrt(real_integ**2 + imag_integ**2).to(device)\n",
    "    angle = torch.arctan(imag_integ/real_integ).to(device)\n",
    "    \n",
    "    # Mean S & angle\n",
    "    S = torch.sum(S)/(batch_size*seq_len)\n",
    "    angle = torch.sum(angle)/(batch_size*seq_len)\n",
    "    \n",
    "    \n",
    "    return S, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53b8b25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 100.0%\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.0%\n",
      "\n",
      "CPU times: user 3.02 s, sys: 50.3 ms, total: 3.07 s\n",
      "Wall time: 845 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test over test loader\n",
    "correct1 = 0\n",
    "correct2 = 0\n",
    "for X, y in test_loader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "    X, y = X.to(device), y.to(device)\n",
    "    S, angle = S_overlap(y, y, X)  # Accuracy by equation (11) Main Article       \n",
    "    correct1 += S\n",
    "    correct2 += angle\n",
    "correct1 /= len(test_loader)\n",
    "correct2 /= len(test_loader)\n",
    "print(f\"Test Error: \\n Accuracy: {(100*correct1):>0.1f}%\\n\")# Should be 100% because y=y => main of |S| = 1\n",
    "print(f\"Test Error: \\n Accuracy: {(correct2):>0.1f}%\\n\")# Should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94dd93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment=\"trash\")  # To use tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ccac99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in train_loader:\n",
    "    writer.add_graph(model,X)  # to draw diagram model\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4501d2",
   "metadata": {},
   "source": [
    "## Train & Test loop definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "37c0e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader)#len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.squeeze().to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X.float()).squeeze()\n",
    "        loss = loss_fn(pred, y.float())\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    writer.add_scalar(\"Loss/train\", loss, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f25084d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correctS, correct_phase = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            S, angle = S_overlap(y, pred,X)  \n",
    "            correctS += S\n",
    "            correct_phase += angle\n",
    "    \n",
    "    correctS /= num_batches\n",
    "    correct_phase /= num_batches\n",
    "    test_loss /= num_batches\n",
    "    \n",
    "    writer.add_scalar('Accuracy Magnitude |S| /test', 100*correctS, epoch)  # Should be 100%\n",
    "    writer.add_scalar('Accuracy phase /test', correct_phase, epoch)  # Should be 0\n",
    "    writer.add_scalar(\"Loss/validation\", test_loss, epoch)\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy Magnitude |S|: {(100*correctS):>0.1f}%\")\n",
    "    print(f\"Test Error: \\n Accuracy phase: {(correct_phase):>0.1f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eebf1e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9169ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.108901  [    0/  560]\n",
      "loss: 0.107287  [  100/  560]\n",
      "loss: 0.071403  [  200/  560]\n",
      "loss: 0.068194  [  300/  560]\n",
      "loss: 0.065636  [  400/  560]\n",
      "loss: 0.056550  [  500/  560]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 36.4%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1\n",
      "\n",
      "CPU times: user 2h 15min 1s, sys: 12.2 s, total: 2h 15min 13s\n",
      "Wall time: 34min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 1\n",
    "for epoch in range(0,epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, optimizer)\n",
    "    test(val_loader, model, criterion)\n",
    "    \n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, '../../Models/06-08-23_290EPOCHS.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee11b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function and optimizer\n",
    "#criterion = nn.MSELoss().to(device)\n",
    "##optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)  #weight_decay=0.01 <- default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d58e7d",
   "metadata": {},
   "source": [
    "## Accuracy Test New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(dataloader, model, loss_fn):\n",
    "    '''\n",
    "    Same as test function but without writer to tensorboard\n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correctS, correct_phase = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            S, angle = S_overlap(y,pred)  \n",
    "            correctS += S\n",
    "            correct_phase += angle\n",
    "    \n",
    "    correctS /= num_batches\n",
    "    correct_phase /= num_batches\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy Magnitude |S|: {(100*correctS):>0.1f}%\")\n",
    "    print(f\"Test Error: \\n Accuracy phase: {(correct_phase):>0.1f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e21259",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1(test_loader, model2, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20d6c9",
   "metadata": {},
   "source": [
    "|Model Name: 06-08-23_--EPOCHS.pth|\n",
    "|--- |\n",
    "\n",
    "|Epoch | Accuracy Magnitude | Accuracy phase |\n",
    "| --- | --- | --- |\n",
    "|220 | 94.1%| 0.0015 |\n",
    "|240 | 94.3%| -0.014 |\n",
    "|260 | 94.4%| -0.003 |\n",
    "|290 | 94.6%| 0.0001|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37deac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../Models/06-08-23_290EPOCHS.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc71434",
   "metadata": {},
   "source": [
    "## Predictions wavepackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in test_loader:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    \n",
    "    Entrada = X\n",
    "    \n",
    "    Salida = y\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        Prediccion = model(X.float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91296a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Entrada.shape)\n",
    "print(Prediccion.shape)\n",
    "print(Salida.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b71b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_n = np.linspace(-1.5,1.5,32)\n",
    "\n",
    "time = int(105)\n",
    "\n",
    "In_real_vis = Entrada[2,time,0:32].detach().numpy()\n",
    "In_imag_vis = Entrada[2,time,32:64].detach().numpy()\n",
    "Pote = Entrada[2,time,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis = Salida[2,time,0:32].detach().numpy()\n",
    "Ou_imag_vis = Salida[2,time,32:64].detach().numpy()\n",
    "Pote_next = Entrada[2,time+1,64:96].detach().numpy()\n",
    "\n",
    "Pred_real_vis = Prediccion[2,time,0:32].detach().numpy()\n",
    "Pred_imag_vis = Prediccion[2,time,32:64].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2)\n",
    "\n",
    "# Lenght: au -> Angstroms\n",
    "axs[0,0].plot(r_n, Pote*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "axs[0,0].plot(r_n, In_real_vis*20, label=\"$\\psi_{real}(r, t)$\", color=color[0])  # Escaled\n",
    "\n",
    "\n",
    "axs[0,1].plot(r_n, Pote*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "axs[0,1].plot(r_n, In_imag_vis*20, label=\"$\\psi_{imag}(r, t)$\", color =color[1])  # Escaled\n",
    "\n",
    "#axs[0].plot(r_n, Pote_next*(1/1.5936e-3), \"-\", label=\"V(r,t)\", color=color[3])\n",
    "axs[1,0].plot(r_n, Ou_real_vis*20, label=\"$\\psi_{real}(r, t+1)_{True}$\", color=color[0])  # Escaled\n",
    "axs[1,0].scatter(r_n, Pred_real_vis*20, label=\"$\\psi_{real}(r, t+1)_{LSTM}$\", color=color[4], marker='.')  # Escaled\n",
    " \n",
    "\n",
    "axs[1,1].plot(r_n, Ou_imag_vis*20, label=\"$\\psi_{imag}(r, t+1)_{True}$\", color =color[1])  # Escaled\n",
    "axs[1,1].scatter(r_n, Pred_imag_vis*20, label=\"$\\psi_{imag}(r, t+1)_{LSTM}$\", color =color[4], marker='.')  # Escaled\n",
    "\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    ax.set_ylim([-35,50])\n",
    "    ax.legend()\n",
    "    ax.set(xlabel='Position [$\\AA$]')\n",
    "    ax.label_outer()\n",
    " \n",
    "\n",
    "plt.gcf().set_size_inches(8, 5.33)\n",
    "plt.legend()    \n",
    "plt.show()\n",
    "plt.savefig('/home/jessica/Tesis/img/tesis/model/1step4.png', dpi=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba7acd",
   "metadata": {},
   "source": [
    "## Predictions density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in test_loader:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    \n",
    "    Entrada = X\n",
    "    \n",
    "    Salida = y\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        Prediccion = model(X.float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------- t=0\n",
    "In_real_vis0 = Entrada[2,0,0:32].detach().numpy()\n",
    "In_imag_vis0 = Entrada[2,0,32:64].detach().numpy()\n",
    "In_dens0 = (np.abs(np.vectorize(complex)(In_real_vis0,In_imag_vis0)))**2\n",
    "\n",
    "Pote0 = Entrada[2,0,64:96].detach().numpy()\n",
    "\n",
    "\n",
    "#------------ t=40 fs\n",
    "Ou_real_vis0 = Salida[2,40,0:32].detach().numpy()\n",
    "Ou_imag_vis0 = Salida[2,40,32:64].detach().numpy()\n",
    "Ou_dens0 = (np.abs(np.vectorize(complex)(Ou_real_vis0,Ou_imag_vis0)))**2\n",
    "      \n",
    "Pred_real_vis0 = Prediccion[2,40,0:32].detach().numpy()\n",
    "Pred_imag_vis0 = Prediccion[2,40,32:64].detach().numpy()\n",
    "Pred_dens0 = (np.abs(np.vectorize(complex)(Pred_real_vis0,Pred_imag_vis0)))**2\n",
    "\n",
    "#-------------- t=80 fs\n",
    "In_real_vis1 = Entrada[2,80,0:32].detach().numpy()\n",
    "In_imag_vis1 = Entrada[2,80,32:64].detach().numpy()\n",
    "Pote1 = Entrada[2,80,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis1 = Salida[2,80,0:32].detach().numpy()\n",
    "Ou_imag_vis1 = Salida[2,80,32:64].detach().numpy()\n",
    "Ou_dens1 = (np.abs(np.vectorize(complex)(Ou_real_vis1,Ou_imag_vis1)))**2\n",
    "\n",
    "Pred_real_vis1 = Prediccion[2,80,0:32].detach().numpy()\n",
    "Pred_imag_vis1 = Prediccion[2,80,32:64].detach().numpy()\n",
    "Pred_dens1 = (np.abs(np.vectorize(complex)(Pred_real_vis1,Pred_imag_vis1)))**2\n",
    "\n",
    "#-------------- t=120 fs\n",
    "In_real_vis2 = Entrada[2,120,0:32].detach().numpy()\n",
    "In_imag_vis2 = Entrada[2,120,32:64].detach().numpy()\n",
    "Pote2 = Entrada[2,120,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis2 = Salida[2,120,0:32].detach().numpy()\n",
    "Ou_imag_vis2 = Salida[2,120,32:64].detach().numpy()\n",
    "Ou_dens2 = (np.abs(np.vectorize(complex)(Ou_real_vis2,Ou_imag_vis2)))**2\n",
    "\n",
    "Pred_real_vis2 = Prediccion[2,120,0:32].detach().numpy()\n",
    "Pred_imag_vis2 = Prediccion[2,120,32:64].detach().numpy()\n",
    "Pred_dens2 = (np.abs(np.vectorize(complex)(Pred_real_vis2,Pred_imag_vis2)))**2\n",
    "\n",
    "#-------------- t=160 fs\n",
    "In_real_vis3 = Entrada[2,160,0:32].detach().numpy()\n",
    "In_imag_vis3 = Entrada[2,160,32:64].detach().numpy()\n",
    "Pote3 = Entrada[2,160,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis3 = Salida[2,160,0:32].detach().numpy()\n",
    "Ou_imag_vis3 = Salida[2,160,32:64].detach().numpy()\n",
    "Ou_dens3 = (np.abs(np.vectorize(complex)(Ou_real_vis3,Ou_imag_vis3)))**2\n",
    "\n",
    "Pred_real_vis3 = Prediccion[2,160,0:32].detach().numpy()\n",
    "Pred_imag_vis3 = Prediccion[2,160,32:64].detach().numpy()\n",
    "Pred_dens3 = (np.abs(np.vectorize(complex)(Pred_real_vis3,Pred_imag_vis3)))**2\n",
    "\n",
    "#-------------- t=200 fs\n",
    "In_real_vis4 = Entrada[2,199,0:32].detach().numpy()\n",
    "In_imag_vis4 = Entrada[2,199,32:64].detach().numpy()\n",
    "Pote4 = Entrada[2,199,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis4 = Salida[2,199,0:32].detach().numpy()\n",
    "Ou_imag_vis4 = Salida[2,199,32:64].detach().numpy()\n",
    "Ou_dens4 = (np.abs(np.vectorize(complex)(Ou_real_vis4,Ou_imag_vis4)))**2\n",
    "\n",
    "Pred_real_vis4 = Prediccion[2,199,0:32].detach().numpy()\n",
    "Pred_imag_vis4 = Prediccion[2,199,32:64].detach().numpy()\n",
    "Pred_dens4 = (np.abs(np.vectorize(complex)(Pred_real_vis4,Pred_imag_vis4)))**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73757fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2)\n",
    "\n",
    "    \n",
    "# Time: fs -> au, Lenght: au -> Angstroms, Energy: au -> kcal/mol\n",
    "ax[0,0].plot(r_n, Pote0*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "ax[0,0].plot(r_n, In_dens0*10, label=\"$|\\psi_{initial}|^{2}$\")\n",
    "ax[0,0].set_title(\"$t=0 fs$\")\n",
    "\n",
    "\n",
    "\n",
    "ax[0,1].plot(r_n, Pote0*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "ax[0,1].scatter(r_n, Pred_dens0*10, label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[0,1].plot(r_n, Ou_dens0*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[0,1].set_title(\"$t=40 fs$\")\n",
    "\n",
    "ax[1,0].plot(r_n, Pote1*(1/1.5936e-3), \"-\", label=\"$V(r, t)$\", color=color[3])\n",
    "ax[1,0].scatter(r_n, Pred_dens1*10, label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[1,0].plot(r_n, Ou_dens1*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[1,0].set_title(\"$t=80 fs$\")\n",
    "\n",
    "ax[1,1].plot(r_n, Pote2*(1/1.5936e-3), \"-\", label=\"$V(r, t)$\", color=color[3])\n",
    "ax[1,1].scatter(r_n, Pred_dens2*(10), label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[1,1].plot(r_n, Ou_dens2*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[1,1].set_title(\"$t=120 fs$\")\n",
    "\n",
    "ax[2,0].plot(r_n, Pote3*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "ax[2,0].scatter(r_n, Pred_dens3*(10), label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[2,0].plot(r_n, Ou_dens3*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[2,0].set_title(\"$t=160 fs$\")\n",
    "\n",
    "ax[2,1].plot(r_n, Pote4*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "ax[2,1].scatter(r_n, Pred_dens4*(10), label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[2,1].plot(r_n, Ou_dens4*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[2,1].set_title(\"$t=200 fs$\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for axr1 in ax:\n",
    "    for axr11 in axr1:\n",
    "        axr11.set_ylim([-5, 50])\n",
    "        axr11.legend()\n",
    "        axr11.set(xlabel='Position [$\\AA$]')\n",
    "        \n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in ax.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "    \n",
    "plt.gcf().set_size_inches(8, 10)\n",
    "#plt.legend()    \n",
    "plt.show()\n",
    "#plt.savefig('/home/jessica/Tesis/img/tesis/model/trajDens11.png', dpi=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8001ef1",
   "metadata": {},
   "source": [
    "### Saving data to animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74042eba",
   "metadata": {},
   "source": [
    " #### Inf about X,y predictions\n",
    " \n",
    " `Entrada[no. batch: from 0 to 9, time: from 0 to 200,(real part, imag part, potential)]`  \n",
    " `Salida[no. batch: from 0 to 9, time: from 0 to 200,(real part, imag part)]`  \n",
    " `Prediccion[no. batch: from 0 to 9, time: from 0 to 200,(real part, imag part)]`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e2b77",
   "metadata": {},
   "source": [
    "#### Torch to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86edd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPred = Prediccion.numpy()  # By model real & imag part\n",
    "newSal = Salida.numpy()  # Analitical real & imag part\n",
    "Poten = Entrada[:,:,64:96].numpy()  # Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4bc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_path = '../Animacion/ModelLSTM-32size'  # animation data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(anim_path+'/prediccion.npy'), 'wb') as f:\n",
    "    np.save(f, newPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be5fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(anim_path+'/salida.npy'), 'wb') as f:\n",
    "    np.save(f, newSal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bcba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(anim_path+'/potencial.npy'), 'wb') as f:\n",
    "    np.save(f, Poten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e2526",
   "metadata": {},
   "source": [
    "## New trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a34d2d",
   "metadata": {},
   "source": [
    "Para asegurar que la red funciona xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b04fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '../../NewTrajectories/data'  # Directory where are a total new trajectory\n",
    "seq_len = 200  # How many time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c70e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_newTest = Propagator_Dataset(data=path_test, targets=path_test, transform=True, sequence_len=seq_len, total_data = 1*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33257888",
   "metadata": {},
   "outputs": [],
   "source": [
    "newTraj = DataLoader(dataset_newTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc0643",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in newTraj:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    \n",
    "    Entrada = X\n",
    "    \n",
    "    Salida = y\n",
    "    with torch.inference_mode():\n",
    "        Prediccion = model(X.float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Entrada.shape)\n",
    "print(Prediccion.shape)\n",
    "print(Salida.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4951f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_n = np.linspace(-1.5,1.5,32)\n",
    "\n",
    "time = int(60)  # from 0 to 199 fs\n",
    "\n",
    "In_real_vis = Entrada[0,time,0:32].detach().numpy()\n",
    "In_imag_vis = Entrada[0,time,32:64].detach().numpy()\n",
    "Pote = Entrada[0,time,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis = Salida[0,time,0:32].detach().numpy()\n",
    "Ou_imag_vis = Salida[0,time,32:64].detach().numpy()\n",
    "Pote_next = Entrada[0,time+1,64:96].detach().numpy()\n",
    "\n",
    "Pred_real_vis = Prediccion[0,time,0:32].detach().numpy()\n",
    "Pred_imag_vis = Prediccion[0,time,32:64].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e628b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2)\n",
    "\n",
    "# Lenght: au -> Angstroms\n",
    "axs[0,0].plot(r_n, Pote*(1/1.5936e-3), \"-\", label=\"V(r,t)\")\n",
    "axs[0,0].plot(r_n, In_real_vis*20, label=\"$\\psi_{r}(r, t)$\")  # Escaled\n",
    "\n",
    "\n",
    "axs[0,1].plot(r_n, Pote*(1/1.5936e-3), \"-\", label=\"V(r,t)\")\n",
    "axs[0,1].plot(r_n, In_imag_vis*20, label=\"$\\psi_{i}(r, t)$\")  # Escaled\n",
    "\n",
    "#axs[0].plot(r_n, Pote_next*(1/1.5936e-3), \"-\", label=\"V(r,t)\", color=color[3])\n",
    "axs[1,0].plot(r_n, Ou_real_vis*20, label=\"$\\psi_{r}(r, t+1)_{True}$\")  # Escaled\n",
    "axs[1,0].scatter(r_n, Pred_real_vis*20, label=\"$\\psi_{r}(r, t+1)_{LSTM}$\", marker='.')  # Escaled\n",
    "\n",
    "\n",
    "axs[1,1].plot(r_n, Ou_imag_vis*20, label=\"$\\psi_{i}(r, t+1)_{True}$\")  # Escaled\n",
    "axs[1,1].scatter(r_n, Pred_imag_vis*20, label=\"$\\psi_{i}(r, t+1)_{LSTM}$\", marker='.')  # Escaled\n",
    "\n",
    "for axr1 in axs:\n",
    "    for axr11 in axr1:\n",
    "        axr11.set_ylim([-20, 60])\n",
    "        axr11.legend()\n",
    "        axr11.set(xlabel='Position [$\\AA$]', ylabel='Energy [Kcal/mol]')\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.gcf().set_size_inches(9, 5)\n",
    "plt.legend()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73d7cc",
   "metadata": {},
   "source": [
    "yes it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50e24d",
   "metadata": {},
   "source": [
    "## Loss and S\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb353e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80014a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fileS1 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug06.csv'\n",
    "fileS2 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug12-S.csv.csv'\n",
    "\n",
    "fileT1 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug06-tetha.csv'\n",
    "fileT2 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug12-tetha.csv'\n",
    "\n",
    "fileLTra1 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug06-lossTrain.csv'\n",
    "fileLTra2 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug12-lossTrain.csv'\n",
    "\n",
    "fileLTe1 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug06-lossTest.csv'\n",
    "fileLTe2 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug12-lossTest.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#headers = ['Wall time', 'Step', 'Value']\n",
    "\n",
    "dfS1 = pd.read_csv(fileS1)\n",
    "dfS2 = pd.read_csv(fileS2)\n",
    "\n",
    "dfT1 = pd.read_csv(fileT1)\n",
    "dfT2 = pd.read_csv(fileT2)\n",
    "\n",
    "dfLTra1 = pd.read_csv(fileLTra1)\n",
    "dfLTra2 = pd.read_csv(fileLTra2)\n",
    "\n",
    "dfLTe1 = pd.read_csv(fileLTe1)\n",
    "dfLTe2 = pd.read_csv(fileLTe2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88828d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS = pd.concat([dfS1, dfS2], ignore_index=True, sort=False)\n",
    "dfth = pd.concat([dfT1, dfT2], ignore_index=True, sort=False)\n",
    "dfLTra = pd.concat([dfLTra1, dfLTra2], ignore_index=True, sort=False)\n",
    "dfLTe = pd.concat([dfLTe1, dfLTe2], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebedbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfS.plot(x = 'Step', y = 'Value')\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].plot(dfS[\"Step\"], dfS[\"Value\"]*0.01, color=color[2])\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Absolute Magnitude $|S|$')\n",
    "\n",
    "ax[1].plot(dfS[\"Step\"], dfth[\"Value\"], color=color[2])\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel(r'Phase $\\theta$')\n",
    "\n",
    "\n",
    "plt.gcf().set_size_inches(11, 4)\n",
    "plt.savefig('/home/jessica/Tesis/img/tesis/S-plot.png', dpi=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a77187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tb_smooth(scalars: list[float], weight: float) -> list[float]:  # Weight between 0 and 1\n",
    "    \"\"\"\n",
    "\n",
    "    ref: https://stackoverflow.com/questions/42011419/is-it-possible-to-call-tensorboard-smooth-function-manually\n",
    "\n",
    "    :param scalars:\n",
    "    :param weight:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed: list = []\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "anu = my_tb_smooth(dfLTra[\"Value\"], 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ada353",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(dfS[\"Step\"], anu, color=color[2], label='Train')\n",
    "ax.plot(dfS[\"Step\"], dfLTe[\"Value\"], color=color[4], label='Test')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches(6, 4)\n",
    "plt.savefig('/home/jessica/Tesis/img/tesis/Loss-plot.png', dpi=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe32c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286dc5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01e984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b45c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b411a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
