{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d0a5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.sampler import SequentialSampler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import integrate\n",
    "\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "#import matplotlib.colors as mcolors\n",
    "#from matplotlib import rcParams\n",
    "\n",
    "#import os\n",
    "#-----\n",
    "\n",
    "\n",
    "# Enable interactive plot\n",
    "#%matplotlib notebook\n",
    "#plt.style.use('pusheen')  # to poster\n",
    "color = ['#83b692','#f9ada0', '#f9627d', '#c65b7c', '#5b3758']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15517338",
   "metadata": {},
   "source": [
    "from matplotlib import rc\n",
    "\n",
    "rc('text', usetex=True)\n",
    "rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "\n",
    "color1 = ['#ff595e','#ffca3a','#8ac926','#1982c4','#6a4c93']\n",
    "color = ['#83b692','#f9ada0', '#f9627d', '#c65b7c', '#5b3758']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6cd442",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15a6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=200  # number of steps on trajectories\n",
    "n_grid = 32  # number of points on grid\n",
    "delta = True # True: y_pred = Psi_t -Psi_{t-1}; else: y_pred = Psi_t \n",
    "\n",
    "if delta == True:\n",
    "    path_dat = '../DataLoader/Data/datadelta.h5'\n",
    "else:\n",
    "    path_dat = '../DataLoader/Data/data.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6643fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Propagator_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, path, data, targets, transform=True):\n",
    "        \n",
    "        self.data = data  # path of data X\n",
    "        self.targets = targets  # path of labels y\n",
    "        self.transform = transform  # to tensor\n",
    "        \n",
    "        self.hf = h5py.File(path, 'r')  # reading data\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        X = self.hf.get(self.data)[index]\n",
    "        y = self.hf.get(self.targets)[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            X = torch.tensor(X)\n",
    "            y = torch.tensor(y)\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        \n",
    "        tot = len(self.hf.get(self.data))\n",
    "        #tot = 100\n",
    "        \n",
    "        return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e090cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Propagator_Dataset(path=path_dat, data='dataset_X', targets='dataset_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11a37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of data  8000\n"
     ]
    }
   ],
   "source": [
    "dataset_size = len(dataset)\n",
    "print('Total of data ', dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b6edf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.1\n",
    "validation_split = 0.2  \n",
    "shuffle_dataset = False\n",
    "random_seed= 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ceb51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data indices for training and validation splits:\n",
    "indices = list(range(dataset_size))\n",
    "split_val = int(np.floor(validation_split * dataset_size))\n",
    "split_test = int(np.floor(test_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "\n",
    "test_indices = indices[0:split_test] \n",
    "val_indices = indices[split_test:split_test+split_val]   \n",
    "train_indices = indices[split_test+split_val:]\n",
    "\n",
    "#train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae55936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of train samples: 5600\n",
      "Total of validation samples: 1600\n",
      "Total of test samples: 800\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total of train samples: {len(train_sampler)}\")\n",
    "print(f\"Total of validation samples: {len(val_sampler)}\")\n",
    "print(f\"Total of test samples: {len(test_sampler)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29dafb6",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7fb09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd0c6c7",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db763be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler)\n",
    "test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c493b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "Shape of X in train loader: torch.Size([10, 200, 96])\n",
      "Shape of y in train loader: torch.Size([10, 200, 64])\n",
      "Batch size: 10\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_loader:\n",
    "    print(\"Train data:\")\n",
    "    print(f\"Shape of X in train loader: {X.shape}\")\n",
    "    print(f\"Shape of y in train loader: {y.shape}\")\n",
    "    print(f\"Batch size: {X.size(0)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3216f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display features and label.\n",
    "train_features, train_labels = next(iter(train_loader))\n",
    "\n",
    "X_vis = train_features[0].squeeze()\n",
    "y_vis = train_labels[0].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60e84b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_n = torch.linspace(-1.5,1.5,32)\n",
    "time = int(0)  # from 0 to 199\n",
    "\n",
    "In_real_vis = X_vis[time,0:n_grid]\n",
    "In_imag_vis = X_vis[time,n_grid:n_grid*2]\n",
    "In_pote = X_vis[time,n_grid*2:]\n",
    "\n",
    "Ou_real_vis = y_vis[time,0:n_grid]\n",
    "Ou_imag_vis = y_vis[time,n_grid:n_grid*2]\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "\n",
    "# Lenght: au -> Angstroms & au -> kcal/mol\n",
    "axs[0].plot(r_n, In_pote*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "axs[0].plot(r_n, In_real_vis*30, label=\"$\\psi_{real}(r, t)$\", color = color[0])  # Escaled\n",
    "axs[0].plot(r_n, In_imag_vis*30, label=\"$\\psi_{imag}(r, t)$\", color=color[1])  # Escaled\n",
    "axs[0].set_title(\"Input\")\n",
    "\n",
    "axs[1].plot(r_n, (In_real_vis + Ou_real_vis)*30, label=\"$\\psi_{real}(r, t+1)$\", color = color[0])  # Escaled\n",
    "axs[1].plot(r_n, (In_imag_vis + Ou_imag_vis)*30, label=\"$\\psi_{imag}(r, t+1)$\", color = color[1])  # Escaled\n",
    "axs[1].set_title(\"Output\")\n",
    "\n",
    "\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    ax.set_ylim([-15, 50])\n",
    "    ax.legend()\n",
    "    ax.set(xlabel='Position [$\\AA$]', ylabel='Energy [Kcal/mol]')\n",
    "\n",
    "plt.gcf().set_size_inches(8, 3)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dae950",
   "metadata": {},
   "source": [
    "## LSTM model\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95dad5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a3c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1716ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_output, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_output = num_output  # number of output\n",
    "        self.num_layers = num_layers  # number of layers\n",
    "        self.input_size = input_size  # input size\n",
    "        self.hidden_size = hidden_size  # hidden state\n",
    "        self.seq_length = seq_length  # sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True).to(device) #lstm\n",
    "        \n",
    "        #self.fc_1 =  nn.Linear(hidden_size, 1024) #fully connected 1\n",
    "\n",
    "        #self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_output).to(device) #fully connected last layer\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        #hn = hn.view(-1,self.hidden_size) #reshaping the data for Dense layer next\n",
    "        #out = self.relu(hn)\n",
    "        #out = self.fc_1(out) #first Dense\n",
    "        #out = self.relu(output) #relu\n",
    "        out = self.fc(output) #Final Output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "203deddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = n_grid*3  # number of features: 32 real part +32 complex part +32 potential\n",
    "hidden_size = 1024  # number of features in hidden state\n",
    "num_layers = 2  # number of stacked lstm layers\n",
    "num_output = n_grid*2  # number of output: 32 real part + 32 complex part\n",
    "sequence_len = seq_len # lenght of time steps (1 fs each one) total 5 fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baeb44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(num_output, input_size, hidden_size, num_layers, sequence_len) #our lstm class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b5990f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function and optimizer\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)  #weight_decay=0.01 <- default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f90b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('../../src/Models/06-08-23_290EPOCHS.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "191f61c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(\n",
      "  (lstm): LSTM(96, 1024, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=1024, out_features=64, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a434ec8",
   "metadata": {},
   "source": [
    "## Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13608c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S_overlap(Psi_true, Psi_ANN, X):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    Psi_true: Evolution of wavepacket from dataset test, Shape: (batch size, sequence lenght, 64)\n",
    "    Psi_ANN: Evolution of wavepacket predicted with the model, Shape: (batch size, sequence lenght, 64)\n",
    "    X : Evolution of wavepacket at time t-1\n",
    "    \n",
    "    Output:\n",
    "    S: Absolute magnitude\n",
    "    angle: phase\n",
    "    Characterizes the quality of the predictions. See equation (11) of Main article\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Psi_true_re = Psi_true[:,:,0:n_grid] + X[:,:,0:n_grid]   # realpart of wavepacket predicted\n",
    "    Psi_true_im = Psi_true[:,:,n_grid:n_grid*2] + X[:,:,n_grid:n_grid*2]  # imaginary part of wavepacket predicted \n",
    "    Psi_t = torch.view_as_complex(torch.stack((Psi_true_re,Psi_true_im), -1)).to(device)\n",
    "    \n",
    "    Psi_ANN_re = Psi_ANN[:,:,0:n_grid]+ X[:,:,0:n_grid]  # realpart of wavepacket predicted\n",
    "    Psi_ANN_im = -(Psi_ANN[:,:,n_grid:n_grid*2]+ X[:,:,n_grid:n_grid*2])  # imaginary part of wavepacket predicted (- because conjugate)\n",
    "    Psi_A = torch.view_as_complex(torch.stack((Psi_ANN_re,Psi_ANN_im), -1)).to(device)\n",
    "    \n",
    "    overl = Psi_A*Psi_t\n",
    "    \n",
    "    # Integrate over r (real integral + complex integral)\n",
    "    # Trapezoid method in the grid r_n (angstroms -> au)\n",
    "    \n",
    "    r_n = (torch.linspace(-1.5,1.5,32)*(1/0.5291775)).to(device)\n",
    "    overl_real = overl.real\n",
    "    overl_imag = overl.imag\n",
    "    \n",
    "    real_integ = torch.trapz(overl_real, r_n).to(device)\n",
    "    imag_integ = torch.trapz(overl_imag, r_n).to(device)\n",
    "    \n",
    "    # Covert to phase and magnitude of the complex result\n",
    "    S =  torch.sqrt(real_integ**2 + imag_integ**2).to(device)\n",
    "    angle = torch.arctan(imag_integ/real_integ).to(device)\n",
    "    \n",
    "    # Mean S & angle\n",
    "    S = torch.sum(S)/(batch_size*seq_len)\n",
    "    angle = torch.sum(angle)/(batch_size*seq_len)\n",
    "    \n",
    "    \n",
    "    return S, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53b8b25f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 100.0%\n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.0%\n",
      "\n",
      "CPU times: user 3.02 s, sys: 50.3 ms, total: 3.07 s\n",
      "Wall time: 845 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test over test loader\n",
    "correct1 = 0\n",
    "correct2 = 0\n",
    "for X, y in test_loader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "    X, y = X.to(device), y.to(device)\n",
    "    S, angle = S_overlap(y, y, X)  # Accuracy by equation (11) Main Article       \n",
    "    correct1 += S\n",
    "    correct2 += angle\n",
    "correct1 /= len(test_loader)\n",
    "correct2 /= len(test_loader)\n",
    "print(f\"Test Error: \\n Accuracy: {(100*correct1):>0.1f}%\\n\")# Should be 100% because y=y => main of |S| = 1\n",
    "print(f\"Test Error: \\n Accuracy: {(correct2):>0.1f}%\\n\")# Should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "94dd93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment=\"trash\")  # To use tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ccac99ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in train_loader:\n",
    "    writer.add_graph(model,X)  # to draw diagram model\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4501d2",
   "metadata": {},
   "source": [
    "## Train & Test loop definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37c0e2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader)#len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.squeeze().to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X.float()).squeeze()\n",
    "        loss = loss_fn(pred, y.float())\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    writer.add_scalar(\"Loss/train\", loss, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f25084d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correctS, correct_phase = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            S, angle = S_overlap(y, pred,X)  \n",
    "            correctS += S\n",
    "            correct_phase += angle\n",
    "    \n",
    "    correctS /= num_batches\n",
    "    correct_phase /= num_batches\n",
    "    test_loss /= num_batches\n",
    "    \n",
    "    writer.add_scalar('Accuracy Magnitude |S| /test', 100*correctS, epoch)  # Should be 100%\n",
    "    writer.add_scalar('Accuracy phase /test', correct_phase, epoch)  # Should be 0\n",
    "    writer.add_scalar(\"Loss/validation\", test_loss, epoch)\n",
    "\n",
    "    \n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy Magnitude |S|: {(100*correctS):>0.1f}%\")\n",
    "    print(f\"Test Error: \\n Accuracy phase: {(correct_phase):>0.1f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eebf1e",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9169ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.108901  [    0/  560]\n",
      "loss: 0.107287  [  100/  560]\n",
      "loss: 0.071403  [  200/  560]\n",
      "loss: 0.068194  [  300/  560]\n",
      "loss: 0.065636  [  400/  560]\n",
      "loss: 0.056550  [  500/  560]\n",
      "Test Error: \n",
      " Accuracy Magnitude |S|: 36.4%\n",
      "Test Error: \n",
      " Accuracy phase: -0.1\n",
      "\n",
      "CPU times: user 2h 15min 1s, sys: 12.2 s, total: 2h 15min 13s\n",
      "Wall time: 34min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "epochs = 1\n",
    "for epoch in range(0,epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, criterion, optimizer)\n",
    "    test(val_loader, model, criterion)\n",
    "    \n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, '../../Models/06-08-23_290EPOCHS.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee11b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function and optimizer\n",
    "#criterion = nn.MSELoss().to(device)\n",
    "##optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)  #weight_decay=0.01 <- default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d58e7d",
   "metadata": {},
   "source": [
    "## Accuracy Test New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "827e4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1(dataloader, model, loss_fn):\n",
    "    '''\n",
    "    Same as test function but without writer to tensorboard\n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correctS, correct_phase = 0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X.float())\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            S, angle = S_overlap(y,pred)  \n",
    "            correctS += S\n",
    "            correct_phase += angle\n",
    "    \n",
    "    correctS /= num_batches\n",
    "    correct_phase /= num_batches\n",
    "\n",
    "    print(f\"Test Error: \\n Accuracy Magnitude |S|: {(100*correctS):>0.1f}%\")\n",
    "    print(f\"Test Error: \\n Accuracy phase: {(correct_phase):>0.1f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e21259",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1(test_loader, model2, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c20d6c9",
   "metadata": {},
   "source": [
    "|Model Name: 06-08-23_--EPOCHS.pth|\n",
    "|--- |\n",
    "\n",
    "|Epoch | Accuracy Magnitude | Accuracy phase |\n",
    "| --- | --- | --- |\n",
    "|220 | 94.1%| 0.0015 |\n",
    "|240 | 94.3%| -0.014 |\n",
    "|260 | 94.4%| -0.003 |\n",
    "|290 | 94.6%| 0.0001|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37deac8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Models/06-08-23_290EPOCHS.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_400545/3195647540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Models/06-08-23_290EPOCHS.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Models/06-08-23_290EPOCHS.pth'"
     ]
    }
   ],
   "source": [
    "model = torch.load('../Models/06-08-23_290EPOCHS.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc71434",
   "metadata": {},
   "source": [
    "## Predictions wavepackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in test_loader:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    \n",
    "    Entrada = X\n",
    "    \n",
    "    Salida = y\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        Prediccion = model(X.float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91296a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Entrada.shape)\n",
    "print(Prediccion.shape)\n",
    "print(Salida.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b71b18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_n = np.linspace(-1.5,1.5,32)\n",
    "\n",
    "time = int(105)\n",
    "\n",
    "In_real_vis = Entrada[2,time,0:32].detach().numpy()\n",
    "In_imag_vis = Entrada[2,time,32:64].detach().numpy()\n",
    "Pote = Entrada[2,time,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis = Salida[2,time,0:32].detach().numpy()\n",
    "Ou_imag_vis = Salida[2,time,32:64].detach().numpy()\n",
    "Pote_next = Entrada[2,time+1,64:96].detach().numpy()\n",
    "\n",
    "Pred_real_vis = Prediccion[2,time,0:32].detach().numpy()\n",
    "Pred_imag_vis = Prediccion[2,time,32:64].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000d4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2)\n",
    "\n",
    "# Lenght: au -> Angstroms\n",
    "axs[0,0].plot(r_n, Pote*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "axs[0,0].plot(r_n, In_real_vis*20, label=\"$\\psi_{real}(r, t)$\", color=color[0])  # Escaled\n",
    "\n",
    "\n",
    "axs[0,1].plot(r_n, Pote*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "axs[0,1].plot(r_n, In_imag_vis*20, label=\"$\\psi_{imag}(r, t)$\", color =color[1])  # Escaled\n",
    "\n",
    "#axs[0].plot(r_n, Pote_next*(1/1.5936e-3), \"-\", label=\"V(r,t)\", color=color[3])\n",
    "axs[1,0].plot(r_n, Ou_real_vis*20, label=\"$\\psi_{real}(r, t+1)_{True}$\", color=color[0])  # Escaled\n",
    "axs[1,0].scatter(r_n, Pred_real_vis*20, label=\"$\\psi_{real}(r, t+1)_{LSTM}$\", color=color[4], marker='.')  # Escaled\n",
    " \n",
    "\n",
    "axs[1,1].plot(r_n, Ou_imag_vis*20, label=\"$\\psi_{imag}(r, t+1)_{True}$\", color =color[1])  # Escaled\n",
    "axs[1,1].scatter(r_n, Pred_imag_vis*20, label=\"$\\psi_{imag}(r, t+1)_{LSTM}$\", color =color[4], marker='.')  # Escaled\n",
    "\n",
    "\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    ax.set_ylim([-35,50])\n",
    "    ax.legend()\n",
    "    ax.set(xlabel='Position [$\\AA$]')\n",
    "    ax.label_outer()\n",
    " \n",
    "\n",
    "plt.gcf().set_size_inches(8, 5.33)\n",
    "plt.legend()    \n",
    "plt.show()\n",
    "plt.savefig('/home/jessica/Tesis/img/tesis/model/1step4.png', dpi=700)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ba7acd",
   "metadata": {},
   "source": [
    "## Predictions density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in test_loader:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    \n",
    "    Entrada = X\n",
    "    \n",
    "    Salida = y\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        Prediccion = model(X.float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------- t=0\n",
    "In_real_vis0 = Entrada[2,0,0:32].detach().numpy()\n",
    "In_imag_vis0 = Entrada[2,0,32:64].detach().numpy()\n",
    "In_dens0 = (np.abs(np.vectorize(complex)(In_real_vis0,In_imag_vis0)))**2\n",
    "\n",
    "Pote0 = Entrada[2,0,64:96].detach().numpy()\n",
    "\n",
    "\n",
    "#------------ t=40 fs\n",
    "Ou_real_vis0 = Salida[2,40,0:32].detach().numpy()\n",
    "Ou_imag_vis0 = Salida[2,40,32:64].detach().numpy()\n",
    "Ou_dens0 = (np.abs(np.vectorize(complex)(Ou_real_vis0,Ou_imag_vis0)))**2\n",
    "      \n",
    "Pred_real_vis0 = Prediccion[2,40,0:32].detach().numpy()\n",
    "Pred_imag_vis0 = Prediccion[2,40,32:64].detach().numpy()\n",
    "Pred_dens0 = (np.abs(np.vectorize(complex)(Pred_real_vis0,Pred_imag_vis0)))**2\n",
    "\n",
    "#-------------- t=80 fs\n",
    "In_real_vis1 = Entrada[2,80,0:32].detach().numpy()\n",
    "In_imag_vis1 = Entrada[2,80,32:64].detach().numpy()\n",
    "Pote1 = Entrada[2,80,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis1 = Salida[2,80,0:32].detach().numpy()\n",
    "Ou_imag_vis1 = Salida[2,80,32:64].detach().numpy()\n",
    "Ou_dens1 = (np.abs(np.vectorize(complex)(Ou_real_vis1,Ou_imag_vis1)))**2\n",
    "\n",
    "Pred_real_vis1 = Prediccion[2,80,0:32].detach().numpy()\n",
    "Pred_imag_vis1 = Prediccion[2,80,32:64].detach().numpy()\n",
    "Pred_dens1 = (np.abs(np.vectorize(complex)(Pred_real_vis1,Pred_imag_vis1)))**2\n",
    "\n",
    "#-------------- t=120 fs\n",
    "In_real_vis2 = Entrada[2,120,0:32].detach().numpy()\n",
    "In_imag_vis2 = Entrada[2,120,32:64].detach().numpy()\n",
    "Pote2 = Entrada[2,120,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis2 = Salida[2,120,0:32].detach().numpy()\n",
    "Ou_imag_vis2 = Salida[2,120,32:64].detach().numpy()\n",
    "Ou_dens2 = (np.abs(np.vectorize(complex)(Ou_real_vis2,Ou_imag_vis2)))**2\n",
    "\n",
    "Pred_real_vis2 = Prediccion[2,120,0:32].detach().numpy()\n",
    "Pred_imag_vis2 = Prediccion[2,120,32:64].detach().numpy()\n",
    "Pred_dens2 = (np.abs(np.vectorize(complex)(Pred_real_vis2,Pred_imag_vis2)))**2\n",
    "\n",
    "#-------------- t=160 fs\n",
    "In_real_vis3 = Entrada[2,160,0:32].detach().numpy()\n",
    "In_imag_vis3 = Entrada[2,160,32:64].detach().numpy()\n",
    "Pote3 = Entrada[2,160,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis3 = Salida[2,160,0:32].detach().numpy()\n",
    "Ou_imag_vis3 = Salida[2,160,32:64].detach().numpy()\n",
    "Ou_dens3 = (np.abs(np.vectorize(complex)(Ou_real_vis3,Ou_imag_vis3)))**2\n",
    "\n",
    "Pred_real_vis3 = Prediccion[2,160,0:32].detach().numpy()\n",
    "Pred_imag_vis3 = Prediccion[2,160,32:64].detach().numpy()\n",
    "Pred_dens3 = (np.abs(np.vectorize(complex)(Pred_real_vis3,Pred_imag_vis3)))**2\n",
    "\n",
    "#-------------- t=200 fs\n",
    "In_real_vis4 = Entrada[2,199,0:32].detach().numpy()\n",
    "In_imag_vis4 = Entrada[2,199,32:64].detach().numpy()\n",
    "Pote4 = Entrada[2,199,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis4 = Salida[2,199,0:32].detach().numpy()\n",
    "Ou_imag_vis4 = Salida[2,199,32:64].detach().numpy()\n",
    "Ou_dens4 = (np.abs(np.vectorize(complex)(Ou_real_vis4,Ou_imag_vis4)))**2\n",
    "\n",
    "Pred_real_vis4 = Prediccion[2,199,0:32].detach().numpy()\n",
    "Pred_imag_vis4 = Prediccion[2,199,32:64].detach().numpy()\n",
    "Pred_dens4 = (np.abs(np.vectorize(complex)(Pred_real_vis4,Pred_imag_vis4)))**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73757fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3,2)\n",
    "\n",
    "    \n",
    "# Time: fs -> au, Lenght: au -> Angstroms, Energy: au -> kcal/mol\n",
    "ax[0,0].plot(r_n, Pote0*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "ax[0,0].plot(r_n, In_dens0*10, label=\"$|\\psi_{initial}|^{2}$\")\n",
    "ax[0,0].set_title(\"$t=0 fs$\")\n",
    "\n",
    "\n",
    "\n",
    "ax[0,1].plot(r_n, Pote0*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "ax[0,1].scatter(r_n, Pred_dens0*10, label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[0,1].plot(r_n, Ou_dens0*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[0,1].set_title(\"$t=40 fs$\")\n",
    "\n",
    "ax[1,0].plot(r_n, Pote1*(1/1.5936e-3), \"-\", label=\"$V(r, t)$\", color=color[3])\n",
    "ax[1,0].scatter(r_n, Pred_dens1*10, label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[1,0].plot(r_n, Ou_dens1*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[1,0].set_title(\"$t=80 fs$\")\n",
    "\n",
    "ax[1,1].plot(r_n, Pote2*(1/1.5936e-3), \"-\", label=\"$V(r, t)$\", color=color[3])\n",
    "ax[1,1].scatter(r_n, Pred_dens2*(10), label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[1,1].plot(r_n, Ou_dens2*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[1,1].set_title(\"$t=120 fs$\")\n",
    "\n",
    "ax[2,0].plot(r_n, Pote3*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "ax[2,0].scatter(r_n, Pred_dens3*(10), label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[2,0].plot(r_n, Ou_dens3*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[2,0].set_title(\"$t=160 fs$\")\n",
    "\n",
    "ax[2,1].plot(r_n, Pote4*(1/1.5936e-3), \"-\", label=\"$V(r,t)$\", color=color[3])\n",
    "ax[2,1].scatter(r_n, Pred_dens4*(10), label=\"$|\\psi_{LSTM}|^{2}$\", color=color[4], marker='.')\n",
    "ax[2,1].plot(r_n, Ou_dens4*10, label=\"$|\\psi_{True}|^{2}$\")\n",
    "ax[2,1].set_title(\"$t=200 fs$\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for axr1 in ax:\n",
    "    for axr11 in axr1:\n",
    "        axr11.set_ylim([-5, 50])\n",
    "        axr11.legend()\n",
    "        axr11.set(xlabel='Position [$\\AA$]')\n",
    "        \n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in ax.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "    \n",
    "plt.gcf().set_size_inches(8, 10)\n",
    "#plt.legend()    \n",
    "plt.show()\n",
    "#plt.savefig('/home/jessica/Tesis/img/tesis/model/trajDens11.png', dpi=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8001ef1",
   "metadata": {},
   "source": [
    "### Saving data to animation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74042eba",
   "metadata": {},
   "source": [
    " #### Inf about X,y predictions\n",
    " \n",
    " `Entrada[no. batch: from 0 to 9, time: from 0 to 200,(real part, imag part, potential)]`  \n",
    " `Salida[no. batch: from 0 to 9, time: from 0 to 200,(real part, imag part)]`  \n",
    " `Prediccion[no. batch: from 0 to 9, time: from 0 to 200,(real part, imag part)]`  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e2b77",
   "metadata": {},
   "source": [
    "#### Torch to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86edd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "newPred = Prediccion.numpy()  # By model real & imag part\n",
    "newSal = Salida.numpy()  # Analitical real & imag part\n",
    "Poten = Entrada[:,:,64:96].numpy()  # Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4bc4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_path = '../Animacion/ModelLSTM-32size'  # animation data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(anim_path+'/prediccion.npy'), 'wb') as f:\n",
    "    np.save(f, newPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be5fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(anim_path+'/salida.npy'), 'wb') as f:\n",
    "    np.save(f, newSal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bcba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(anim_path+'/potencial.npy'), 'wb') as f:\n",
    "    np.save(f, Poten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91c98c",
   "metadata": {},
   "source": [
    "### Saving data to animation for animation python file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3b7c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save data in a file\n",
    "directory = '../Predictions/'\n",
    "# Creating the file\n",
    "h5f = h5py.File(directory+time.strftime(\"%Y%m%d-%H%M%S\")+'.h5', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b610fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving X data\n",
    "h5f.create_dataset('dataset_X', data=Entrada)\n",
    "# Saving y data\n",
    "h5f.create_dataset('dataset_y', data=Salida)\n",
    "h5f.create_dataset('dataset_p', data=Prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82e2526",
   "metadata": {},
   "source": [
    "## New trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a34d2d",
   "metadata": {},
   "source": [
    "Para asegurar que la red funciona xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b04fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = '../../NewTrajectories/data'  # Directory where are a total new trajectory\n",
    "seq_len = 200  # How many time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c70e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_newTest = Propagator_Dataset(data=path_test, targets=path_test, transform=True, sequence_len=seq_len, total_data = 1*200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33257888",
   "metadata": {},
   "outputs": [],
   "source": [
    "newTraj = DataLoader(dataset_newTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fc0643",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X,y in newTraj:\n",
    "    X, y = X.to(device), y.to(device)\n",
    "    \n",
    "    Entrada = X\n",
    "    \n",
    "    Salida = y\n",
    "    with torch.inference_mode():\n",
    "        Prediccion = model(X.float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bc1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Entrada.shape)\n",
    "print(Prediccion.shape)\n",
    "print(Salida.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4951f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_n = np.linspace(-1.5,1.5,32)\n",
    "\n",
    "time = int(60)  # from 0 to 199 fs\n",
    "\n",
    "In_real_vis = Entrada[0,time,0:32].detach().numpy()\n",
    "In_imag_vis = Entrada[0,time,32:64].detach().numpy()\n",
    "Pote = Entrada[0,time,64:96].detach().numpy()\n",
    "\n",
    "Ou_real_vis = Salida[0,time,0:32].detach().numpy()\n",
    "Ou_imag_vis = Salida[0,time,32:64].detach().numpy()\n",
    "Pote_next = Entrada[0,time+1,64:96].detach().numpy()\n",
    "\n",
    "Pred_real_vis = Prediccion[0,time,0:32].detach().numpy()\n",
    "Pred_imag_vis = Prediccion[0,time,32:64].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e628b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2)\n",
    "\n",
    "# Lenght: au -> Angstroms\n",
    "axs[0,0].plot(r_n, Pote*(1/1.5936e-3), \"-\", label=\"V(r,t)\")\n",
    "axs[0,0].plot(r_n, In_real_vis*20, label=\"$\\psi_{r}(r, t)$\")  # Escaled\n",
    "\n",
    "\n",
    "axs[0,1].plot(r_n, Pote*(1/1.5936e-3), \"-\", label=\"V(r,t)\")\n",
    "axs[0,1].plot(r_n, In_imag_vis*20, label=\"$\\psi_{i}(r, t)$\")  # Escaled\n",
    "\n",
    "#axs[0].plot(r_n, Pote_next*(1/1.5936e-3), \"-\", label=\"V(r,t)\", color=color[3])\n",
    "axs[1,0].plot(r_n, Ou_real_vis*20, label=\"$\\psi_{r}(r, t+1)_{True}$\")  # Escaled\n",
    "axs[1,0].scatter(r_n, Pred_real_vis*20, label=\"$\\psi_{r}(r, t+1)_{LSTM}$\", marker='.')  # Escaled\n",
    "\n",
    "\n",
    "axs[1,1].plot(r_n, Ou_imag_vis*20, label=\"$\\psi_{i}(r, t+1)_{True}$\")  # Escaled\n",
    "axs[1,1].scatter(r_n, Pred_imag_vis*20, label=\"$\\psi_{i}(r, t+1)_{LSTM}$\", marker='.')  # Escaled\n",
    "\n",
    "for axr1 in axs:\n",
    "    for axr11 in axr1:\n",
    "        axr11.set_ylim([-20, 60])\n",
    "        axr11.legend()\n",
    "        axr11.set(xlabel='Position [$\\AA$]', ylabel='Energy [Kcal/mol]')\n",
    "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "for ax in axs.flat:\n",
    "    ax.label_outer()\n",
    "    \n",
    "plt.gcf().set_size_inches(9, 5)\n",
    "plt.legend()    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a73d7cc",
   "metadata": {},
   "source": [
    "yes it works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf50e24d",
   "metadata": {},
   "source": [
    "## Loss and S\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb353e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80014a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "fileS1 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug06.csv'\n",
    "fileS2 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug12-S.csv.csv'\n",
    "\n",
    "fileT1 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug06-tetha.csv'\n",
    "fileT2 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug12-tetha.csv'\n",
    "\n",
    "fileLTra1 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug06-lossTrain.csv'\n",
    "fileLTra2 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug12-lossTrain.csv'\n",
    "\n",
    "fileLTe1 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug06-lossTest.csv'\n",
    "fileLTe2 = '../runs/Aug06_16-54-53_Aldos-MBP.fritz.boxUpdate2LSTM_1024neu_seq200_BATCH_10_LR_1E-4_4700DATA/Aug12-lossTest.csv'\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a5601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#headers = ['Wall time', 'Step', 'Value']\n",
    "\n",
    "dfS1 = pd.read_csv(fileS1)\n",
    "dfS2 = pd.read_csv(fileS2)\n",
    "\n",
    "dfT1 = pd.read_csv(fileT1)\n",
    "dfT2 = pd.read_csv(fileT2)\n",
    "\n",
    "dfLTra1 = pd.read_csv(fileLTra1)\n",
    "dfLTra2 = pd.read_csv(fileLTra2)\n",
    "\n",
    "dfLTe1 = pd.read_csv(fileLTe1)\n",
    "dfLTe2 = pd.read_csv(fileLTe2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88828d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS = pd.concat([dfS1, dfS2], ignore_index=True, sort=False)\n",
    "dfth = pd.concat([dfT1, dfT2], ignore_index=True, sort=False)\n",
    "dfLTra = pd.concat([dfLTra1, dfLTra2], ignore_index=True, sort=False)\n",
    "dfLTe = pd.concat([dfLTe1, dfLTe2], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510d863",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfS.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebedbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfS.plot(x = 'Step', y = 'Value')\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].plot(dfS[\"Step\"], dfS[\"Value\"]*0.01, color=color[2])\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Absolute Magnitude $|S|$')\n",
    "\n",
    "ax[1].plot(dfS[\"Step\"], dfth[\"Value\"], color=color[2])\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel(r'Phase $\\theta$')\n",
    "\n",
    "\n",
    "plt.gcf().set_size_inches(11, 4)\n",
    "plt.savefig('/home/jessica/Tesis/img/tesis/S-plot.png', dpi=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a77187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tb_smooth(scalars: list[float], weight: float) -> list[float]:  # Weight between 0 and 1\n",
    "    \"\"\"\n",
    "\n",
    "    ref: https://stackoverflow.com/questions/42011419/is-it-possible-to-call-tensorboard-smooth-function-manually\n",
    "\n",
    "    :param scalars:\n",
    "    :param weight:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    last = scalars[0]  # First value in the plot (first timestep)\n",
    "    smoothed: list = []\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  # Calculate smoothed value\n",
    "        smoothed.append(smoothed_val)                        # Save it\n",
    "        last = smoothed_val                                  # Anchor the last smoothed value\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "anu = my_tb_smooth(dfLTra[\"Value\"], 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ada353",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(dfS[\"Step\"], anu, color=color[2], label='Train')\n",
    "ax.plot(dfS[\"Step\"], dfLTe[\"Value\"], color=color[4], label='Test')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.gcf().set_size_inches(6, 4)\n",
    "plt.savefig('/home/jessica/Tesis/img/tesis/Loss-plot.png', dpi=700)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe32c15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286dc5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01e984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0b45c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b411a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
